{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72cf8eb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T05:11:56.150043Z",
     "iopub.status.busy": "2025-06-22T05:11:56.149545Z",
     "iopub.status.idle": "2025-06-22T05:16:56.005256Z",
     "shell.execute_reply": "2025-06-22T05:16:56.004043Z"
    },
    "papermill": {
     "duration": 299.868307,
     "end_time": "2025-06-22T05:16:56.013925",
     "exception": false,
     "start_time": "2025-06-22T05:11:56.145618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multimodal combined JSON file created successfully!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load all feature files\n",
    "with open('/kaggle/input/extracted-features/Textual_Features_RoBERTa.json') as f:\n",
    "    text_data = json.load(f)\n",
    "with open('/kaggle/input/extracted-features/Audio_Features_OpenSMILE.json') as f:\n",
    "    audio_data = json.load(f)\n",
    "with open('/kaggle/input/extracted-features/Video_Features_SlowFast.json') as f:  # Assuming video features file\n",
    "    video_data = json.load(f)\n",
    "\n",
    "# Initialize the final combined data structure\n",
    "combined_data = {\"train\": [], \"dev\": [], \"test\": []}\n",
    "\n",
    "# Process each split (train, dev, test)\n",
    "for split in [\"train\", \"dev\", \"test\"]:\n",
    "    # Create lookup dictionaries for audio and video features\n",
    "    audio_lookup = {}\n",
    "    video_lookup = {}\n",
    "    \n",
    "    # Populate audio lookup dictionary\n",
    "    for item in audio_data[split]:\n",
    "        # Find the audio key (e.g., '0_0')\n",
    "        audio_key = next(k for k in item.keys() \n",
    "                         if k != 'y' and k != 'label' and not k.endswith('_opensmile_features'))\n",
    "        \n",
    "        # Store audio path and features\n",
    "        audio_lookup[audio_key] = {\n",
    "            \"path\": item[audio_key],\n",
    "            \"features\": item[f\"{audio_key}_opensmile_features\"]\n",
    "        }\n",
    "    \n",
    "    # Populate video lookup dictionary\n",
    "    for item in video_data[split]:\n",
    "        # Identify base key (e.g., '0_1')\n",
    "        video_key = next(k for k in item.keys() \n",
    "                         if k not in ['y', 'label', 'frames_dir', 'mask_info'] \n",
    "                         and not k.endswith('_slowfast_features'))\n",
    "        \n",
    "        # Store video info and features\n",
    "        video_lookup[video_key] = {\n",
    "            \"video_path\": item[video_key],\n",
    "            \"features\": item[f\"{video_key}__slowfast_features\"],\n",
    "            \"frames_dir\": item[\"frames_dir\"],\n",
    "            \"mask_info\": item[\"mask_info\"]\n",
    "        }\n",
    "    \n",
    "    # Process text items and combine with audio and video\n",
    "    for item in text_data[split]:\n",
    "        # Find the text key (e.g., '0_0')\n",
    "        text_key = next(k for k in item.keys() \n",
    "                        if k != 'y' and k != 'label' and not k.endswith('_RoBERTa'))\n",
    "        \n",
    "        # Check if we have matching audio and video\n",
    "        if text_key in audio_lookup and text_key in video_lookup:\n",
    "            audio_info = audio_lookup[text_key]\n",
    "            video_info = video_lookup[text_key]\n",
    "            \n",
    "            # Concatenate features from all three modalities\n",
    "            combined_features = (\n",
    "                item[f\"{text_key}_RoBERTa\"] + \n",
    "                audio_info[\"features\"] + \n",
    "                video_info[\"features\"]\n",
    "            )\n",
    "            \n",
    "            # Create new combined entry\n",
    "            new_entry = {\n",
    "                text_key: item[text_key],  # Original text\n",
    "                f\"{text_key}_audio_path\": audio_info[\"path\"],\n",
    "                f\"{text_key}_video_path\": video_info[\"video_path\"],  # Video path\n",
    "                \"frames_dir\": video_info[\"frames_dir\"],  # Frames directory\n",
    "                \"mask_info\": video_info[\"mask_info\"],   # Mask info\n",
    "                f\"{text_key}_Concatenated\": combined_features,\n",
    "                \"y\": item[\"y\"],\n",
    "                \"label\": item[\"label\"]\n",
    "            }\n",
    "            \n",
    "            combined_data[split].append(new_entry)\n",
    "\n",
    "# Save the combined data to a new JSON file\n",
    "with open(\"Multimodal_Combined_Features.json\", \"w\") as f:\n",
    "    json.dump(combined_data, f, indent=4)\n",
    "\n",
    "print(\"Multimodal combined JSON file created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f3dfeb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T05:16:56.021795Z",
     "iopub.status.busy": "2025-06-22T05:16:56.021441Z",
     "iopub.status.idle": "2025-06-22T05:21:11.104816Z",
     "shell.execute_reply": "2025-06-22T05:21:11.103753Z"
    },
    "papermill": {
     "duration": 255.089507,
     "end_time": "2025-06-22T05:21:11.107702",
     "exception": false,
     "start_time": "2025-06-22T05:16:56.018195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced JSON file created with speaker information!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the existing text+audio combined features\n",
    "with open('/kaggle/working/Multimodal_Combined_Features.json') as f:\n",
    "    combined_features = json.load(f)\n",
    "\n",
    "# Load the MELD cleaned dataset\n",
    "with open('/kaggle/input/meld-emotion-recognition/JSON files/JSON files/Final Format/MELD_Data_Cleaned_Processed.json') as f:\n",
    "    meld_data = json.load(f)\n",
    "\n",
    "# Create a mapping dictionary for speaker information\n",
    "# Structure: {(split, dia_utt): speaker}\n",
    "speaker_mapping = {}\n",
    "\n",
    "# Process MELD data to create the mapping\n",
    "for item in meld_data['data']:\n",
    "    split = item['split']\n",
    "    dia_utt = f\"{item['dialog']}_{item['utterance']}\"  # e.g., \"0_0\"\n",
    "    speaker = item['speaker']\n",
    "    speaker_mapping[(split, dia_utt)] = speaker\n",
    "\n",
    "# Add speaker information to the combined features\n",
    "for split in [\"train\", \"dev\", \"test\"]:\n",
    "    for entry in combined_features[split]:\n",
    "        # Find the base key (e.g., \"0_0\")\n",
    "        base_key = None\n",
    "        for key in entry.keys():\n",
    "            # Skip known metadata keys and suffixed keys\n",
    "            if key not in ['y', 'label'] and \\\n",
    "               not key.endswith('_audio_path') and \\\n",
    "               not key.endswith('_Concatenated'):\n",
    "                base_key = key\n",
    "                break\n",
    "        \n",
    "        if base_key is None:\n",
    "            print(f\"Warning: Couldn't find base key in entry: {entry}\")\n",
    "            continue\n",
    "        \n",
    "        # Get speaker from mapping\n",
    "        map_key = (split, base_key)\n",
    "        if map_key in speaker_mapping:\n",
    "            entry['speaker'] = speaker_mapping[map_key]\n",
    "        else:\n",
    "            print(f\"Warning: No speaker found for {base_key} in {split} split\")\n",
    "            entry['speaker'] = \"Unknown\"\n",
    "\n",
    "# Save the enhanced combined features\n",
    "with open(\"Enhanced_Combined_Features.json\", \"w\") as f:\n",
    "    json.dump(combined_features, f, indent=4)\n",
    "\n",
    "print(\"Enhanced JSON file created with speaker information!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6525542,
     "sourceId": 10730648,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6562401,
     "sourceId": 12243228,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 563.978631,
   "end_time": "2025-06-22T05:21:15.037018",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-22T05:11:51.058387",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
